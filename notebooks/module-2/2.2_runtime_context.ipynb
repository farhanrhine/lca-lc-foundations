{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00525f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13dbd3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ColourContext:\n",
    "    favourite_colour: str = \"blue\"\n",
    "    least_favourite_colour: str = \"yellow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c565aee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(model=\"meta-llama/llama-4-maverick-17b-128e-instruct\",\n",
    "                        model_provider=\"groq\",\n",
    "                        temperature = 0,\n",
    "                        max_retries=3,\n",
    "                        timeout=60,\n",
    "                        max_tokens=300\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03be72fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    context_schema=ColourContext  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eec82bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is my favourite colour?\")]},\n",
    "    context=ColourContext()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9e923d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='What is my favourite colour?', additional_kwargs={}, response_metadata={}, id='7a98c7ea-6597-48fc-a383-800565c19e11'),\n",
      "              AIMessage(content=\"I don't have any information about your personal preferences, including your favourite colour. I'm a large language model, I don't have the ability to know you or your preferences unless you tell me. Would you like to share your favourite colour with me?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 16, 'total_tokens': 65, 'completion_time': 0.072008985, 'completion_tokens_details': None, 'prompt_time': 0.000239656, 'prompt_tokens_details': None, 'queue_time': 0.048982304, 'total_time': 0.072248641}, 'model_name': 'meta-llama/llama-4-maverick-17b-128e-instruct', 'system_fingerprint': 'fp_d2c1f7e199', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3be0-91f7-7b12-88d4-6cb95484d238-0', usage_metadata={'input_tokens': 16, 'output_tokens': 49, 'total_tokens': 65})]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24874360",
   "metadata": {},
   "source": [
    "## Accessing Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dca527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool, ToolRuntime\n",
    "\n",
    "@tool\n",
    "def get_favourite_colour(runtime: ToolRuntime) -> str:\n",
    "    \"\"\"Get the favourite colour of the user\"\"\"\n",
    "    return runtime.context.favourite_colour\n",
    "\n",
    "@tool\n",
    "def get_least_favourite_colour(runtime: ToolRuntime) -> str:\n",
    "    \"\"\"Get the least favourite colour of the user\"\"\"\n",
    "    return runtime.context.least_favourite_colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce743296",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_favourite_colour, get_least_favourite_colour],\n",
    "    context_schema=ColourContext\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f07e137d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='What is my favourite colour?', additional_kwargs={}, response_metadata={}, id='6f821394-8f0c-4eb7-b352-21f439053bf1'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'nmg3w7t1g', 'function': {'arguments': '{}', 'name': 'get_favourite_colour'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 735, 'total_tokens': 757, 'completion_time': 0.032860938, 'completion_tokens_details': None, 'prompt_time': 0.015791769, 'prompt_tokens_details': None, 'queue_time': 0.049167801, 'total_time': 0.048652707}, 'model_name': 'meta-llama/llama-4-maverick-17b-128e-instruct', 'system_fingerprint': 'fp_d2c1f7e199', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3be1-6202-7dc2-acfe-8ec8dd2dacd6-0', tool_calls=[{'name': 'get_favourite_colour', 'args': {}, 'id': 'nmg3w7t1g', 'type': 'tool_call'}], usage_metadata={'input_tokens': 735, 'output_tokens': 22, 'total_tokens': 757}),\n",
      "              ToolMessage(content='blue', name='get_favourite_colour', id='d0f7ca83-fba0-4614-a6f9-6527e0bf7de2', tool_call_id='nmg3w7t1g'),\n",
      "              AIMessage(content='Your favourite colour is blue.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 779, 'total_tokens': 786, 'completion_time': 0.019292738, 'completion_tokens_details': None, 'prompt_time': 0.0170638, 'prompt_tokens_details': None, 'queue_time': 0.05004151, 'total_time': 0.036356538}, 'model_name': 'meta-llama/llama-4-maverick-17b-128e-instruct', 'system_fingerprint': 'fp_d2c1f7e199', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3be1-63c3-7d22-ba4b-94b16fc68418-0', usage_metadata={'input_tokens': 779, 'output_tokens': 7, 'total_tokens': 786})]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\lca-lc-foundations\\.venv\\Lib\\site-packages\\pydantic\\main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='context', input_value=ColourContext(favourite_c...vourite_colour='yellow'), input_type=ColourContext])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "response = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is my favourite colour?\")]},\n",
    "    context=ColourContext()\n",
    ")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f68fc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='What is my favourite colour?', additional_kwargs={}, response_metadata={}, id='6cc62747-c768-4698-a93b-b9e82b8a131d'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'd4qzjw2ca', 'function': {'arguments': '{}', 'name': 'get_favourite_colour'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 735, 'total_tokens': 757, 'completion_time': 0.033283412, 'completion_tokens_details': None, 'prompt_time': 0.015452103, 'prompt_tokens_details': None, 'queue_time': 0.054394297, 'total_time': 0.048735515}, 'model_name': 'meta-llama/llama-4-maverick-17b-128e-instruct', 'system_fingerprint': 'fp_d2c1f7e199', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3be1-ee39-7e70-a5d4-f5ce16be8b23-0', tool_calls=[{'name': 'get_favourite_colour', 'args': {}, 'id': 'd4qzjw2ca', 'type': 'tool_call'}], usage_metadata={'input_tokens': 735, 'output_tokens': 22, 'total_tokens': 757}),\n",
      "              ToolMessage(content='green', name='get_favourite_colour', id='c5d3c56f-03cb-4756-9b7a-e75fb9e29322', tool_call_id='d4qzjw2ca'),\n",
      "              AIMessage(content='Your favourite colour is green.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 779, 'total_tokens': 786, 'completion_time': 0.018066565, 'completion_tokens_details': None, 'prompt_time': 0.018100785, 'prompt_tokens_details': None, 'queue_time': 0.054512065, 'total_time': 0.03616735}, 'model_name': 'meta-llama/llama-4-maverick-17b-128e-instruct', 'system_fingerprint': 'fp_d2c1f7e199', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b3be1-f06b-7493-95f4-7ed8f990dc59-0', usage_metadata={'input_tokens': 779, 'output_tokens': 7, 'total_tokens': 786})]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\lca-lc-foundations\\.venv\\Lib\\site-packages\\pydantic\\main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='context', input_value=ColourContext(favourite_c...vourite_colour='yellow'), input_type=ColourContext])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "response = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is my favourite colour?\")]},\n",
    "    context=ColourContext(favourite_colour=\"green\")\n",
    ")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4adca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-foundations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
